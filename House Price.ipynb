{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOUSE PRICES: ADVANCE REGRESSION TECHNIQUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing test and train files\n",
    "### To remove skewness in SalePrice I took log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "df_y=np.log(df['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing all features into either numerical or categorical feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.dtypes\n",
    "x=pd.DataFrame(data=x,index=None).reset_index()\n",
    "categorical_features=x[x.iloc[:,1]=='object']['index']\n",
    "numerical_feature=df.columns.drop(categorical_features).drop(['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing values\n",
    "   ### For categorical features, I assumed most of the values that are missing tells us that those features are not present in house. Therefore i replaced them with 'None'\n",
    "   ### For numerical features, I replaced missing values with the mean of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = [df,test]\n",
    "for data in combine:\n",
    "    data[categorical_features]=data[categorical_features].fillna('None')\n",
    "    for column in numerical_feature:\n",
    "        data[column]=data[column].fillna((data[column].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers\n",
    "### Using IQR Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\priyanshu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for col in numerical_feature:\n",
    "    IQR=df.describe().iloc[4:7,:][col][2]-df.describe().iloc[4:7,:][col][0]\n",
    "    Ub=df.describe().iloc[4:7,:][col][2]+IQR*1.5\n",
    "    lb=df.describe().iloc[4:7,:][col][0]-IQR*1.5\n",
    "    df[df[col]>Ub][col]=Ub\n",
    "    df[df[col]<lb][col]=lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Encoding\n",
    "### I encoded categorical feature by replacing each unique value of a features, by corresponding average of SalesPrice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={}\n",
    "for column in categorical_features:\n",
    "    dict.update(df.groupby(column)['SalePrice'].mean())\n",
    "    df[column]=df[column].map(dict)\n",
    "    test[column]=test[column].map(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First I divide all features in two list,\n",
    "## all_column contains all those features which are not correlated with any other features,\n",
    "## group contains all those groups of column that have correlation above 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.corr(method='spearman')\n",
    "\n",
    "x=pd.DataFrame(x)\n",
    "group=[]\n",
    "unique=[]\n",
    "corr=[0,0,0]\n",
    "\n",
    "for i in range(81):\n",
    "    unique.append(i)\n",
    "    for j in unique:\n",
    "        \n",
    "        if abs(x.iloc[i,int(j)])>0.4 and abs(x.iloc[i,int(j)])<1:\n",
    "            corr=np.vstack((corr,[x.index[j],x.index[i],x.iloc[i,j]]))\n",
    "            corr=np.vstack((corr,[x.index[j],x.index[j],x.iloc[j,j]]))\n",
    "            \n",
    "            unique.pop()\n",
    "            \n",
    "all_column=[x.index[i] for i in unique]\n",
    "corr=pd.DataFrame(corr).drop(0)\n",
    "\n",
    "for x in corr.iloc[:,0].unique():\n",
    "    group.append(corr[corr.iloc[:,0]==x][1].unique())\n",
    "all_column=[col for col in all_column if col not in corr.iloc[:,0].unique()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now from every group of features in group, I took that one feature which has most influence on SalePrice, and termed that as imp_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_col=[]\n",
    "for groups in group:\n",
    "    \n",
    "    mse=-1\n",
    "    columns='none'\n",
    "    for col in groups:\n",
    "        x_train=df[col].fillna(0)\n",
    "        clf = DecisionTreeRegressor(random_state=0)\n",
    "        clf.fit(x_train.to_frame(),df_y)\n",
    "        y_pred= clf.predict(x_train.to_frame())\n",
    "        if mean_squared_error(df['SalePrice'], y_pred)> mse:\n",
    "            columns=col\n",
    "            mse=mean_squared_error(df['SalePrice'], y_pred)\n",
    "    imp_col.append(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now I added both all_column and imp_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_column=[col for col in all_column if col not in corr.iloc[:,0].unique()]\n",
    "all_column=all_column + imp_col\n",
    "all_column.append('SalePrice')\n",
    "all_column.append('OverallQual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here again I check for any correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=df[all_column].corr(method='spearman')['SalePrice'].sort_values()\n",
    "final_col=corr.index.where(corr>0.3).dropna().drop('SalePrice')\n",
    "\n",
    "final_col=final_col.drop('Exterior1st')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df[final_col]\n",
    "X_test=test[final_col]\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "\n",
    "X_test=pd.DataFrame(X_test,columns=final_col)\n",
    "X_train=pd.DataFrame(X_train,columns=final_col)\n",
    "\n",
    "X_test=X_test.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LinearRegression()\n",
    "lr=LinearRegression()\n",
    "lr.fit(X_train,df_y)\n",
    "y=lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "a=cross_val_score(lr,X_train,df_y,cv=10)\n",
    "a.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tuning of XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:14:21] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    }
   ],
   "source": [
    "model = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    \"learning_rate\"     : [0.05,0.1,0.15,0.2,0.3],\n",
    "    \"max_depth\"         : [3,4,5,6,7,8,9,10],\n",
    "    \"min_child_weight\"  : [2,2.25,2.5],\n",
    "    \"gamma\"             : [0.05,0.1,0.15],\n",
    "    \"colsample_bytree\"  : [0.8,0.9,0.95]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:    4.7s remaining:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:29:07] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=None,\n",
       "                                          objective='reg:linear',\n",
       "                                          random_st...\n",
       "                                          seed=None, silent=None, subsample=1,\n",
       "                                          verbosity=1),\n",
       "                   iid='warn', n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.8, 0.9, 0.95],\n",
       "                                        'gamma': [0.05, 0.1, 0.15],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                                        'min_child_weight': [2, 2.25, 2.5]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=3)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rc=RandomizedSearchCV(model,params,n_iter=5,n_jobs=-1,cv=5,verbose=3)\n",
    "rc.fit(X_train,df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 2.5,\n",
       " 'max_depth': 8,\n",
       " 'learning_rate': 0.1,\n",
       " 'gamma': 0.1,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=0.9, gamma=0.1,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=8, min_child_weight=2.5, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:31:05] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "model=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.9, gamma=0.1,\n",
    "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "             max_depth=8, min_child_weight=2.5, missing=None, n_estimators=100,\n",
    "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "             silent=None, subsample=1, verbosity=1)\n",
    "model.fit(X_train,df_y)\n",
    "y=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"Id\": test[\"Id\"],\n",
    "        \"SalePrice\": np.exp(y)\n",
    "    })\n",
    "submission.to_csv('submission5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
